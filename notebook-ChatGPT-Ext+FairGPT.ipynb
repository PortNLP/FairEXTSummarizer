{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "\n",
    "def contains_only_symbols(input_string):\n",
    "    # Define a regular expression pattern to match symbols\n",
    "    symbol_pattern = r'^[\\W_]+$'\n",
    "\n",
    "    # Use re.match to check if the entire string matches the pattern\n",
    "    if re.match(symbol_pattern, input_string):\n",
    "        return True\n",
    "    elif input_string == '':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def longestSubstring(str1,str2):\n",
    "    seqMatch = SequenceMatcher(None,str1,str2)\n",
    "    match = seqMatch.find_longest_match(0, len(str1), 0, len(str2))\n",
    "    if (match.size!=0):\n",
    "        return str1[match.a: match.a + match.size]\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def find_longest_common_subsequence(str1, str_list):\n",
    "    indices = []\n",
    "    subs = []\n",
    "    loop = 0\n",
    "    while not contains_only_symbols(str1):\n",
    "      if loop > 20:\n",
    "        break\n",
    "      lcs = [\"\"]*len(str_list)\n",
    "      for i, s in enumerate(str_list):\n",
    "          lcs[i] = longestSubstring(str1, s)\n",
    "      idx = lcs.index(max(lcs, key=len))\n",
    "      if not contains_only_symbols(lcs[idx]):  \n",
    "        indices.append(idx)\n",
    "        subs.append(lcs[idx])\n",
    "      str1 = str1.replace(lcs[idx], '')\n",
    "      lcs[idx] = ''\n",
    "      loop += 1\n",
    "    return indices, subs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a609690c46f11a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## ChatGPT-EXT",
   "metadata": {
    "collapsed": false
   },
   "id": "49a0d4b3c48948b6"
  },
  {
   "cell_type": "code",
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "m = 6\n",
    "\n",
    "openai.api_key = \"Your API Key\"\n",
    "\n",
    "# Get the list of files in the directory\n",
    "directory = 'input_docs/docs'\n",
    "file_list = os.listdir(directory)\n",
    "\n",
    "dir_dict = {'White': 'H-A', 'Hisp': 'A-W', 'AA': 'W-H'}\n",
    "\n",
    "for file in file_list[24:]:\n",
    "    df = pd.DataFrame()\n",
    "    docs = pd.read_csv('input_docs/docs/' + file)\n",
    "    dict = {}\n",
    "\n",
    "    for remove_label in ['White', 'Hisp', 'AA']:\n",
    "        docs_filter = docs[docs.label != remove_label]\n",
    "        document = ''\n",
    "        for idx, sentence in enumerate(docs_filter.text, start=1):\n",
    "            document += f\"\\n{idx}. {sentence}\"\n",
    "        for i in range(10):\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an extractive summarizer that follows the output pattern.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"Please extract sentences as the summary. The summary should contain {m} sentences. Document: {document}\"}\n",
    "                ]\n",
    "            )\n",
    "            summary = response.choices[0].message.content\n",
    "            indices, subs = find_longest_common_subsequence(summary, docs['text'].values)\n",
    "\n",
    "            persentage = []\n",
    "            for i in range(len(indices)):\n",
    "                persentage.append(len(subs[i])/len(docs['text'][indices[i]]))\n",
    "            if sum(sorted(persentage, reverse=True)[:6]) > 3:\n",
    "                top_indices = sorted(range(len(persentage)), key=lambda i: persentage[i], reverse=True)[:6]\n",
    "                selected_values = [indices[i] for i in top_indices]\n",
    "                docs.iloc[selected_values].to_csv(f'output_chatGPT/{dir_dict[remove_label]}/{file}', index = False)\n",
    "                break\n",
    "\n",
    "        dict[dir_dict[remove_label]] = response\n",
    "    df = pd.concat([df, pd.DataFrame(dict)])\n",
    "    df.to_csv(f'output_chatGPT/model_outputs/{file}', index=True)        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## FairGPT",
   "metadata": {
    "collapsed": false
   },
   "id": "4eb924fde54c3b4"
  },
  {
   "cell_type": "code",
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "m = 6\n",
    "\n",
    "openai.api_key = \"Your API Key\"\n",
    "\n",
    "# Get the list of files in the directory\n",
    "directory = 'input_docs/docs'\n",
    "file_list = os.listdir(directory)\n",
    "\n",
    "dir_dict = {'White': 'H-A', 'Hisp': 'A-W', 'AA': 'W-H'}\n",
    "name_dict = {'White': 'White', 'Hisp': 'Hispanic', 'AA': 'African-American'}\n",
    "\n",
    "\n",
    "for file in file_list:\n",
    "    docs = pd.read_csv(directory + '/' + file)\n",
    "    dict = {}\n",
    "\n",
    "    for remove_label in ['White', 'Hisp', 'AA']:\n",
    "        print(remove_label)\n",
    "\n",
    "        labels = list({'White', 'Hisp', 'AA'} - {remove_label})\n",
    "\n",
    "        docs_filter = docs[docs.label == labels[0]]\n",
    "        document_g1 = f'{name_dict[labels[0]]} People: \\n'\n",
    "        for idx, sentence in enumerate(docs_filter.text, start=1):\n",
    "            document_g1 += f\"**{{\\n{idx}. {sentence}}}**\"\n",
    "\n",
    "        docs_filter = docs[docs.label == labels[1]]\n",
    "        document_g2 = f'{name_dict[labels[1]]} People: \\n'\n",
    "        for idx, sentence in enumerate(docs_filter.text, start=1):\n",
    "            document_g2 += f\"**{{\\n{idx}. {sentence}}}**\"\n",
    "\n",
    "        document = document_g1 + '\\n\\n' + document_g2\n",
    "\n",
    "        for i in range(10):\n",
    "            response = openai.ChatCompletion.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are an extractive fair summarizer that follows the output pattern. A fair summarizer should select the same number of sentences from each group of people.\"},\n",
    "                        {\"role\": \"user\", \"content\": f\"Please extract sentences as the summary. The summary should contain {m} sentences which means select {m/2} number of sentences from each group of people to represent the idea of all groups in a fair manner. Document: \\n\\n {document}\"}\n",
    "                    ]\n",
    "                )\n",
    "            summary = response.choices[0].message.content\n",
    "            indices, subs = find_longest_common_subsequence(summary, docs['text'].values)\n",
    "\n",
    "            persentage = []\n",
    "            for j in range(len(indices)):\n",
    "                persentage.append(len(subs[j])/len(docs['text'][indices[j]]))\n",
    "            print(i)\n",
    "            if sum(sorted(persentage, reverse=True)[:6]) > 3:\n",
    "                top_indices = sorted(range(len(persentage)), key=lambda i: persentage[i], reverse=True)[:6]\n",
    "                selected_values = [indices[k] for k in top_indices]\n",
    "                print(i)\n",
    "                if (docs.iloc[selected_values]['label'].value_counts(normalize=True) == 0.5).all():\n",
    "                    docs.iloc[selected_values].to_csv(f'output_fairChatGPT/{dir_dict[remove_label]}/{file}', index = False)\n",
    "                    print(i)\n",
    "                    break\n",
    "                else:\n",
    "                    print(docs.iloc[selected_values]['label'].value_counts(normalize=True))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69552d95e6332a47",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "30bdf6eaa5940e19",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
